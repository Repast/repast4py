== Tutorial 1 - A Simple Model

#QUESTION: Can we include a pointer to where the model code is in the distribution/repository?#

This tutorial will guide you through coding a simple model, focusing on components
and concepts common to every model. The simulation itself consists of a number
of agents moving at random around a two-dimensional grid and logging the aggregate and agent-level
colocation counts. Each timestep the following occurs:

1. All the agents (_walkers_) choose a random direction and move one unit in that direction.
2. All the agents count the number of other agents they _meet_ at their current location by
determining the number of colocated agents at their grid locations.
3. The sum, minimum, and maxiumum number of agents met are calculated across all process ranks, and these 
values are logged as the total, minimum, and maximum `meet` values.

In addition, every 10 timesteps: 

1. The individual agent _meet_ counts are logged across all the process ranks.

The code consists of the following components:

1. A `Walker` class that implements the agent state and behavior.
2. A `Model` class responsible for initialization and managing the simulation.
3. A `restore_walker` function used to create an individual `Walker` when that
`Walker` has moved (i.e., walked) to another process.
4. A `run` function that creates and starts the simulation.
5. An `if __name__ == "__main__"` block that allows the simulation to be run
from the command line.

NOTE: This is the canonical way to organize a Repast4Py simulation: agents implemented as classes,
a _model_-type class to initialize and manage the simulation, a function to handle restoring agents
as they move between processes, and some additional code to run the simulation from the command line. O
f course, in a more complex simulation the responsibilities and behavior of the agent and model classes can be 
factored out into additional classes, functions, and modules as necessary, but the overall
organization remains the same.

=== The Walker Agent

The Walker class implements our Walker agent, encapsulating its:

* State: a count of all the other walkers that it has colocated with, and the walker's current location
* Behavior: moving randomly around a 2D dimensional grid and counting the number
of colocations

As required for all Repast4Py agent implementations, the `Walker` class subclasses
`repast4py.core.Agent`, passing it the components of the unique agent id tuple.


[source,python,numbered]
----
from repast4py.space import DiscretePoint
from repast4py import core
import numpy as np

class Walker(core.Agent):   #<1>

    TYPE = 0    #<2>
    OFFSETS = np.array([-1, 1])    #<3>  

    def __init__(self, local_id: int, rank: int, pt: DiscretePoint):    
        super().__init__(id=local_id, type=Walker.TYPE, rank=rank)    #<4>
        self.pt = pt
        self.meet_count = 0
----
<1> Walker subclasses `repast4py.core.Agent`. Subclassing `Agent` is a requirement for all Repast4Py agent implementations.
<2> `TYPE` is a class variable that defines an agent type id for our walker agent. This is a required
part of the unique agent id tuple (see 4).
<3> `OFFSETS` is a numpy array used in the agent behavior implementation to select the direction to move in. See the discussion of the `walk` method below.
<4> `repast4py.core.Agent` constructor takes 3 arguments: an integer id that uniquely identifes an
agent on the process where it was created, a non-negative integer identifying the type of the agent, and
the rank on which the agent is created. Taken together, these three uniquely identify the agent
across all ranks in the simulation.

The agent's behavior is implemented in the `walk` and the `count_colocations` methods.
In the `walk` method, the agent randomly chooses an offset from its current location (`self.pt`),
adds those offsets to its current location to create a new location, and then moves to that new
location on the grid. The moved-to-location becomes the agent's new current location.

==== Walking the Walker

[source,python,numbered]
----
from repast4py import random    #<1>
from repast4py.space import DiscretePoint
...
OFFSETS = np.array([-1, 1])
...
def walk(self, grid: SharedGrid):    #<2>
    # choose two elements from the OFFSET array
    # to select the direction to walk in the
    # x and y dimensions
    xy_dirs = random.default_rng.choice(Walker.OFFSETS, size=2)    #<3>
    self.pt = grid.move(self, DiscretePoint(self.pt.x + xy_dirs[0], 
                        self.pt.y + xy_dirs[1], 0)) #<4>
----
<1> `repast4py.random` contains an instance of a `numpy.random.Generator` as the module level variable
`default_rng`, as well as a function for intializing this variable. See the numpy https://numpy.org/doc/stable/reference/random/generator.html[random.Generator] api reference for more details.
<2> All the walker agents move on the same grid. An instance of this grid, a `repast4py.space.SharedGrid` object is passed in.
<3> The https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.choice.html#numpy.random.Generator.choice[`numpy.random.Generator.choice`] randomly chooses `size` number of elements
from a numpy array. In this case randomly selecting either -1 or 1 from `OFFSETS`. The
two chosen values correspond to the direction to move along the x and y dimensions, respectively.
<4> `SharedGrid.move` moves an agent to a location in the grid and returns the destination location. Grid locations are represented by a `repast4py.space.DiscretePoint` and an instance of
that with updated new x and y coordinates is passed to the `move` method.


NOTE: Repast4Py provides a default random number generator in `repast4py.random.default_rng`. This
random number generator is initialized when the module is imported, with the current time as the seed.
The seed can also be set by specifying a `random.seed` model input parameter and using Repast4Py's model input parameters utility code. (See <<_running_the_simulation, Running the Simulation>> for more details.) `random.default_rng` is an instance of `numpy.random.Generator`. See the numpy https://numpy.org/doc/stable/reference/random/generator.html[random.Generator] api reference for more information on the available distributions and sampling functions.

==== Logging the Walker

The `count_colocations` method gets the number of other agents at the current location, and
updates both the agent's individual running total of other agents met, as well as a `MeetLog` dataclass
instance that is used to log the total number of meets and the minimum and maximum.


[source,python,numbered]
----
@dataclass
class MeetLog:
    total_meets: int = 0
    min_meets: int = 0
    max_meets: int = 0

...

def count_colocations(self, grid: SharedGrid, meet_log: MeetLog):
    # subtract self
    num_here = grid.get_num_agents(self.pt) - 1    #<1>
    meet_log.total_meets += num_here
    if num_here < meet_log.min_meets:
        meet_log.min_meets = num_here
    if num_here > meet_log.max_meets:
        meet_log.max_meets = num_here
    self.meet_count += num_here
----
<1> `SharedGrid.get_num_agents` returns the number of agents at a specified location.

TIP: To learn more about built-in agent and grid functionality, see the API documentation for `repast4py.core.Agent` and `repast4py.space.SharedGrid`.


As we will see below, the Model class will schedule the execution of these two functions on every agent at every timestep. In this way, each agent executes its behavior each timestep.

==== Serializing the Walker

When a `Walker` walks beyond the bounds of the local grid managed by its current
process rank, or when populating the buffer area of the local grid sections, 
Repast4Py needs to serialize the `Walker` state to a tuple, which is then used
to recreate that `Walker` on a different process. The `Walker.save` method
performs this serialization, saving the agent's unique id, its current meet count,
and location.

[source,python,numbered]
----
def save(self) -> Tuple:
    """Saves the state of this Walker as a Tuple.

    Returns:
        The saved state of this Walker.
    """
    return (self.uid, self.meet_count, self.pt.coordinates)    #<1>
----
<1> Returns the `Walker` state as a tuple. The first element of this
tuple *MUST* be the agent's unique id (`self.uid`). `self.pt` is
an instance of a `DiscretePoint` whose `coordinates` method
returns the point's coordinates as a numpy array.

IMPORTANT: Every agent must implement a `save` method that returns the
state of the agent as a tuple. The first element of this
tuple *MUST* be the agent's unique id (`self.uid`). The remaining elements
should encapsulate any dynamic agent state.

=== The Model Class

The Model class encapsulates the simulation and is responsible for initialization. It schedules events, 
creates agents and the grid the agents inhabit, and manages logging. In addition, the scheduled events
that drive the simulation forward are methods of the `Model` class. 

In the `Model` constructor, we create the simulation schedule, the context that holds
our agents, the grid on which they move, the agents themselves, and the loggers that
we use to log various simulation statistics to files. We begin with the constructor
signature, and the schedule runner creation. 

==== Scheduling Events

The SharedScheduledRunner class encapsulates a dynamic schedule of executable events shared and
synchronized across processes. Events are added to the schedule for execution at a particular _tick_.
The first valid tick is 0. Events will be executed in tick order, earliest before latest. Events
scheduled for the same tick will be executed in the order in which they
were added. If during the execution of a tick, an event is scheduled
before the executing tick (i.e., scheduled to occur in the past) then
that event is ignored. The schedule is synchronized across process ranks
by determining the global cross-process minimum next scheduled event time and executing events
for that time. In this way, no schedule runs ahead of any other. In practice an
event is a no-argument function or method.

[source,python,numbered]
----
def __init__(self, comm: MPI.Intracomm, params: Dict):    #<1>
    # create the schedule
    self.runner = schedule.init_schedule_runner(comm)     #<2>
    self.runner.schedule_repeating_event(1, 1, self.step)    #<3>
    self.runner.schedule_repeating_event(1.1, 10, self.log_agents)
    self.runner.schedule_stop(params['stop.at'])    #<4>
    # once initialized the schedule runner can be accessed with schedule.runner
    schedule.runner().schedule_end_event(self.at_end)    #<5>
----
<1> The Model constructor takes an MPI communicator and a dictionary of model
input parameters as arguments.
<2> Before any events can be scheduled, the schedule runner must be initialized.
<3> Schedules `Model.step` on this instance of the model to execute starting at tick 1 and then every 
tick thereafter. Repeating events are scheduled with `schedule.repeating_event`. The first argument
is the start tick, and the second is the frequency for repeating.
<4> `schedule_stop` schedules the tick at which the simulation should stop. At this tick,
events will no longer be popped off the schedule and executed.
<5> `schedule_end_event` can be used to schedule methods that perform some sort of 
_clean up_ type operation when the simulation ends, closing a log file, for example.
This is called at the time specified in the call to `schedule_stop`.

TIP: Once the default scheduler runner has been initialized with `schedule.init_schedule_runner`, you can get a reference to it with `schedule.runner()`. See the schedule model API documentation for
more information on different ways to schedule events (methods and functions).

IMPORTANT: A simulation stopping time must be set with `schedule_stop`. Without a stopping time
the simulation will continue to run, seeming to hang if there are no events to execute, or
continuing to execute any scheduled events without stopping. The stopping time does not
need to be set during initialization, but can be set during a simulation run when a
stopping condition is reached.

==== Creating the Context and Grid

Once the schedule has been initialized and events have been added, the context, which holds the population of agents, and the grid projection on which the agents move are 
created (contexts and projections are described in xref:overview.adoc#_contexts_and_projections[Contexts and Projections]).

[source,python,numbered]
----
from repast4py import context as ctx
...

# create the context to hold the agents and manage cross process
# synchronization
self.context = ctx.SharedContext(comm)    <1>
# create a bounding box equal to the size of the entire global world grid
box = space.BoundingBox(0, params['world.width'], 0, params['world.height'], 0, 0)    #<2>
# create a SharedGrid of 'box' size with sticky borders that allows multiple agents
# in each grid location.
self.grid = space.SharedGrid(name='grid', bounds=box, borders=space.BorderType.Sticky,
                                occupancy=space.OccupancyType.Multiple, 
                                buffer_size=2, comm=comm)    #<3>
self.context.add_projection(self.grid)    #<4>
----
<1> Creates the xref:overview.adoc#_contexts_and_projections[`SharedContext`] for this
simulation. The `SharedContext` contains the population of agents and manages
synchronization of the projections across ranks.
<2> A BoundingBox is used to initialize the size of Repast4Py's cartesian spaces. Its
arguments are the minimum x coordinate, the extent of the x dimension, and then the same for
the y and z dimensions. Here we create a 2D box (the z extent is 0) starting at (0,0) and
extending for `params['world.width]` in the x dimension and `params['world.height']` in
the y dimension.
<3> `space.SharedGrid` takes a name, its bounds, its border, and occupancy types, as well
as a buffer size, and a communicator as arguments. See the `SharedGrid` API documentation
for a description of these arguments. The concept of a buffer was described in the
xref:overview.adoc#_distributed_simulation[Distributed Simulation] section.
<4> Once a xref:overview.adoc#_contexts_and_projections[projection] has been created
it must be added to the context so that it can be properly synchronized across
processes.

==== Creating the Agents

When creating the agents, we create the number of Walker agents specified in the `walker.count`
input parameter, assigning each a random location. 

[source,python,numbered]
----
rank = comm.Get_rank()
for i in range(params['walker.count']):
    # get a random x,y location in the grid
    pt = self.grid.get_random_local_pt(rng)    #<1>
    # create and add the walker to the context
    walker = Walker(i, rank, pt)    #<2>
    self.context.add(walker)    #<3>
    self.grid.move(walker, pt)  #<4>
----
<1> Gets random location within the grid's local bounds. Each rank is responsible for some subsection of the 
total global grid and `get_random_local_pt` gets a random location within those local bounds.
<2> Creates the Walker, passing it an id, its starting rank, and its current location. See
<<_the_walker_agent>> for more.
<3> Adds the new Walker to the context. Once created, an agent must be added to the context in order to be properly synchronized
and iterated through as part of the agent population.
<4> Move the walker to its starting location.

NOTE: Agents added to a context are also added to any projections in that context. Although
projections have `add` methods for adding agents, these are typically _NOT_ used in a 
simulation.

==== Initializing Logging

Logging refers to gathering simulation output data and writing it to a file. There are
two types of logging supported by Repast4Py.

1. Tabular logging in which the user supplies row values to be logged, and Repast4Py 
concatenates these rows across processes and writes them to a file. This is useful
for logging events and individual agent attributes. See the `repast4py.logging.TabularLogger`
API for more information.

2. Reduce-type logging where the user supplies the aggregate values to be logged
in the form of a Python `dataclasses.dataclass` and Repast4Py performs a cross-process
reduce-type (e.g., summation) operation on those values. To use this
type of logging, you create a _logger_, which is responsible for logging the dataclass field(s)
and performing the reduction operation on the field(s). These loggers are then added to
a `logging.ReducingDataSet`. Calling `logging.ReducingDataSet.log(tick)` will log the
current value of the dataclass field(s) in the loggers and perform the cross-process
reduction. See the `logging` module API for more information.

The Walker Model uses both of these logging types. The first is used to log the individual _meet_count_ of
each agent, and the second to log that total number of meets, as well as the minimum and maximum number.

[source,python,numbered]
----
@dataclass
class MeetLog:    #<1>
    total_meets: int = 0
    min_meets: int = 0
    max_meets: int = 0

...
self.agent_logger = logging.TabularLogger(comm, params['agent_log_file'], 
                                          ['tick', 'agent_id', 'agent_uid_rank', 
                                          'meet_count'])    #<2>
self.meet_log = MeetLog()    #<3>
loggers = logging.create_loggers(self.meet_log, op=MPI.SUM, 
                                 names={'total_meets': 'total'}, rank=rank)    #<4>
loggers += logging.create_loggers(self.meet_log, op=MPI.MIN, 
                                  names={'min_meets': 'min'}, rank=rank)       #<5>
loggers += logging.create_loggers(self.meet_log, op=MPI.MAX, 
                                  names={'max_meets': 'max'}, rank=rank)       #<6>
self.data_set = logging.ReducingDataSet(loggers, MPI.COMM_WORLD, 
                                        params['meet_log_file'])    #<7>
----
<1> MeetLog is the dataclass used by the aggregate reduce logging. As we saw in
<<_logging_the_walker>> each agent updates the shared MeetLog instance as appropriate in
its `count_colocations` method. 
<2> The `TabularLogger` class is used for tabular-style logging. The constructor
arguments are the communicator over which to concatenate all the table's rows and
the column header values. `self.agent_logger` is then used to log the individual
agent meet counts.
<3> Creates the `MeetLog` object that contains the aggregate colocation statistics
that we want to log.
<4> Creates a logger that uses `self.meet_log` as the source of the data to log,
performing a cross process summation (`op=MPI.SUM`) of that data to log, and logs the value 
of the `total` field in `self.meet_log`. The `names` argument specifies 
the fields to log as a dictionary where the key is the dataclass field to log, and
the value is the column header text for that value. 
<5> Creates a logger for the `self.meet_log.min` field, minimizing the value
across processes. The created logger is added to the list of loggers created
in 4.
<6> Creates a logger for the `self.meet_log.max` field, maximizing the value
across processes. The created logger is added to the list of loggers created
in 4.
<7> Creates a `logging.ReducingDataSet` from the list of loggers. `params['meet_log_file]`
is the name of the file to log to.


After the logging is initialized, we log the starting tick 0 state of the 
simulation.

[source,python,numbered]
----
# count the initial colocations at time 0 and log
for walker in self.context.agents():
    walker.count_colocations(self.grid, self.meet_log)    #<1>
self.data_set.log(0)    #<2>
self.meet_log.max_meets = self.meet_log.min_meets = self.meet_log.total_meets = 0   #<3>
self.log_agents()    #<4>
----
<1> Updates `self.meet_log` with each agents colocation data by calling `count_colocations`
on each agent. See <<_logging_the_walker>> for the details.
<2> Logs the current values of the `self.meet_log` by calling `log` on the `self.data_set` `ReducingDataSet`.
The `log` method takes a floating point argument that specifies the tick at which the data was logged (in this case tick 0). 
<3> Resets the `self.meet_log` values back to 0 given that we want to log the data per tick, rather than a running total.
<4> Logs the individual agent meet counts. See the method definition below.

The `log_agents` method logs each agent's `meet_count` using the
`self.agent_logger TabularLogger`.

[source,python,numbered]
----
def log_agents(self):
    tick = self.runner.schedule.tick    #<1>
    for walker in self.context.agents(): #<2>
        self.agent_logger.log_row(tick, walker.id, walker.uid_rank, 
                                  walker.meet_count)    #<3>

    self.agent_logger.write()   #<4>
----
<1> Gets the current tick value
<2> Iterates over all the local agents in the context. `SharedContext.agents()` returns
an iterator over the local agent population.
<3> For each Walker, log the current tick, the Walker's id, its unique id rank,
and its `meet_count` using the `log_row` method. Each call to `log_row` becomes
a row in the tabular output.
<4> Writes the currently logged rows to a file. It is not strictly necessary
to call `write` every time rows are logged as the rows will accumulate until `write`
is eventually called.

==== Scheduled Methods

In <<_scheduling_events>> we saw how to schedule events that repeat and that execute
when the simulation ends. In this model, the events to be scheduled are methods of the
`Model` class. The methods are called according to how they are scheduled, driving the
simulation forward. The first of these, the `step` method, is scheduled to execute starting
at tick 1 and then every tick thereafter.

[source,python,numbered]
----
# scheduled with: self.runner.schedule_repeating_event(1, 1, self.step)
def step(self):
    for walker in self.context.agents():    #<1>
        walker.walk(self.grid)

    self.context.synchronize(restore_walker)    #<2>

    for walker in self.context.agents():    #<3>
        walker.count_colocations(self.grid, self.meet_log)

    tick = self.runner.schedule.tick
    self.data_set.log(tick)    #<4>
    # clear the meet log counts for the next tick
    self.meet_log.max_meets = self.meet_log.min_meets = self.meet_log.total_meets = 0    #<5>
----
<1> Calls `walk` on each `Walker` agent. `self.context.agents` returns an iterator over all the 
agents in the model. See <<_walking_the_walker>> for more information on the `walk` method,
and the `SharedContext` API documenation for more information on the `agents` method.
<2> Synchronizes the state of the simulation across processes using the `restore_walker`
function to restore any `Walkers` that have moved processes. See <<_restoring_walkers>>
for more information.
<3> Updates `self.meet_log` with each agent's colocation data by calling `count_colocations`
on each `Walker`. See <<_logging_the_walker>> for the details.
<4> Logs the current values of the `self.meet_log` by calling `log` on the `self.data_set` `ReducingDataSet`.
As we saw earlier, the `log` method takes a floating point argument that specifies the tick at which the data was logged. 
In this case, we use the current tick value.
<5> Resets the `self.meet_log` values back to 0 because we want to log the data per tick, rather than
a running total.

IMPORTANT: Call `synchronize` on your `SharedContext` whenever you need to synchronize
the state of the simulation across processes. For example, when agents moving on a
grid or space may have crossed into a subsection of the global grid that is 
managed by a different process or when the buffer areas need to be updated.


The second repeating event (`self.runner.schedule_repeating_event(1.1, 10, self.log_agents)`) is
scheduled to call `Model.log_agents` starting at tick 1.1, and then every 10 ticks thereafter. See the discussion
of `log_agents` in <<_initializing_logging>> for more information.

The final event (`self.runner.schedule_end_event(self.at_end)`) is scheduled to call
`Model.at_end` when the simulation ends. This method closes the two logs, 
insuring that any remaining unwritten data is written to their respective
files.

[source,python,numbered]
----
def at_end(self):
    self.data_set.close()
    self.agent_logger.close()
----

IMPORTANT: Do not forget to call `close` on your logging class instances when the simulation ends.


=== Restoring Walkers
The `restore_walker` function is used to create an individual `Walker` when that
`Walker` has moved (i.e., walked) to another process. This function is passed
to the `synchronize` method (i.e., `self.context.synchronize(restore_walker)`)
and is called in the synchronization mechanism. The `restore_walker` function
is the reverse of the `Walker.save` method discussed in <<_serializing_the_walker>>,
unpacking the tuple returned by that to create a `Walker` agent.

[source,python,numbered]
----
walker_cache = {}    #<1>

def restore_walker(walker_data: Tuple):    #<2>
    """
    Args:
        walker_data: tuple containing the data returned by Walker.save.
    """
    # uid is a 3 element tuple: 0 is id, 1 is type, 2 is rank
    uid = walker_data[0]    #<3>
    pt_array = walker_data[2]
    pt = DiscretePoint(pt_array[0], pt_array[1], 0)    #<4>

    if uid in walker_cache:    #<5>
        walker = walker_cache[uid]
    else:    #<6>
        walker = Walker(uid[0], uid[2], pt)
        walker_cache[uid] = walker

    walker.meet_count = walker_data[1]    #<7>
    walker.pt = pt
    return walker
----
<1> We use a caching strategy when restoring Walkers. This
dictionary is the cache of previously created walkers. The dictionary
keys are the Walker unique ids, and the values are the Walker instances.
<2> The `walker_data` tuple is the same tuple as created by the `Walker.save`
method. 
<3> The first element of the tuple is the Walker's unique id. 
<4> Creates a `DiscretePoint` from point coordinate array. This
is the current location of the `Walker` being restored.
<5> Checks if the `Walker` unique id is in the cache. If it is, then retrieve that `Walker`.
<6> If the unique id is not in the cache, then create a `Walker`.
<7> Updates the `Walker` state with the `meet_count` and point
data. 

=== Running the Simulation

The simulation is run from the command line:

`mpirun -n 4 python examples/rndwalk/rndwalk.py examples/rndwalk/random_walk.yaml`

Here we are running the simulation with 4 process ranks and the model input parameters are
in the `examples/rndwalk/random_walk.yaml` file.

[source,yaml,numbered]
----
random.seed: 42
stop.at: 50
walker.count: 1000
world.width: 2000
world.height: 2000
meet_log_file: 'output/meet_log.csv'
agent_log_file: 'output/agent_log.csv'
----

An `if __name__ == '__main__'` code block is used to parse the input parameters and
run the simulation. The `repast4py.parameters` module contains utility functions
for parsing both command line and model input parameter files, including a 
default parser for command line arguments.

[source,python,numbered]
----
if __name__ == "__main__":
    parser = parameters.create_args_parser()    #<1>
    args = parser.parse_args()    #<2>
    params = parameters.init_params(args.parameters_file, args.parameters)    #<3>
    run(params)
----
<1> Creates the default command line argument parser.
<2> Parses the command line into its arguments using that default parser
<3> Creates the model input parameters dictionary from those arguments using
`parameters.init_params`.

The default command line parser created with `parameters.create_args_parser` accepts
a path to a yaml format parameters input file, and a json format dictionary string
that will override parameters in the parameters file.

```
$ python examples/rndwalk/rndwalk.py -h
usage: rndwalk.py [-h] parameters_file [parameters]

positional arguments:
  parameters_file  parameters file (yaml format)
  parameters       json parameters string

optional arguments:
  -h, --help       show this help message and exit
```

`parameters.init_params` takes the parameters file and the json string and creates a dictionary
of model input parameters whose keys are the parameter names and values are the parameter values.
This dictionary is returned by the function and is available via the module itself as `parameters.params`.
For example,

[source,python,numbered]
----
from repast4py import parameters
...
parameters.init_params(args.parameters_file, args.parameters)
...
num_agents = parameters.params['num.agents']
----

If the parameters file or the json input contains a parameter named `random.seed`,
the default random number generator (i.e., `repast4py.random.default_rng`) is initialized
with that seed. See the `repast4py.parameters` API documentation for more information.

Lastly we have a simple `run` function that creates the `Model` class and calls its
`start` method, which starts the simulation by starting schedule execution. This `run` function is called
in the `if __name__ == '__main__'` code block.

[source,python,numbered]
----
def run(params: Dict):
    model = Model(MPI.COMM_WORLD, params)
    model.start()

class Model:

    def start(self):
        self.runner.execute()    #<1>
----
<1> Start the simulation by executing the schedule which
calls the scheduled methods at the appropriate times and frequency.

NOTE: The code in the `run` function could be moved to the `if __name__ == '__main__'` code block,
but it is often useful to have an entry type function that initializes and starts a simulation.


