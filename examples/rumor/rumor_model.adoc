= Rumor Model
Version 1.0 September 2021
:toc2:
:icons: font
:numbered:
:website: http://repast.github.io
:xrefstyle: full
:imagesdir: images
:source-highlighter: pygments

== Overview
The Rumor model is a simple network model that illustrates repast4py's network 
agent-based model features. The simulation models the spread of a rumor through a networked population.
During initialization some number of agents (network nodes) are marked as rumor spreaders. At each iteration of the simulation, a random draw is made to determine if the neighbors of any rumor-spreading nodes have received the rumor. This draw is performed once for each neighbor. After all of the neighbors that can receive the rumor have been processed, the collection of rumor spreaders is updated
to include those nodes that received the rumor.

*This text assumes you have already read the _Repast4Py Users Guide_ up through the
model implementation tutorial.*

The source code for the examples models can be downloaded from TODO: update link [here].

== The Network
The rumor model network is initialized from the `network.txt` file included with the example model.
This file assigns each
node (agent) to a process rank. Repast4py creates a `repast4py.network.SharedNetwork`
from this file, instantiating the nodes on the correct ranks and creating the edges between
the nodes appropriately. When an edge is between nodes on different process ranks (i.e., the
edge crosses process ranks), repast4py will create a _ghost_ node (agent) whose state mirrors that
of the agent on the other process, and create an edge using this ghost. For example, if an edge exists between A and B and A is on rank 1 and B on rank 2, then
repast4py will:

1. Create a ghost of B on rank 1
2. Create a ghost of A on rank 2
3. Create an edge between A and the ghost B on rank 1
4. Create an edge between B and the ghost A on rank 2

For more information about ghost agents and how their state is maintained see the *Distributed Simulation* and
*Distributed Simulation Code Requirements* in the repast4py Users Guide.

The `network.txt` file was created using `rumor.generate_network_file` to distribute a
connected Watts and Strogatz graph generated by networkx across 4 process ranks. `rumor.generate_network_file`
uses repast4py's capability to take a networkx Graph object and distribute it across some specified number of 
process ranks and write it to a file. A model can then create a SharedNetwork instance from such a file.

[source,python,numbered]
----
import networkx as nx
from repast4py.network import write_network, read_network
...
def generate_network_file(fname: str, n_ranks: int, n_agents: int):
    """Generates a network file using repast4py.network.write_network.

    Args:
        fname: the name of the file to write to
        n_ranks: the number of process ranks to distribute the file over
        n_agents: the number of agents (node) in the network
    """
    g = nx.connected_watts_strogatz_graph(n_agents, 2, 0.25)    <1>
    try:
        import nxmetis
        write_network(g, 'rumor_network', fname, n_ranks, partition_method='metis')    <2>
    except ImportError:
        write_network(g, 'rumor_network', fname, n_ranks)    <3>
----
<1> Create a connected Watts and Strogatz graph using networkx. See the networkx https://networkx.org/documentation/stable/reference/generated/networkx.generators.random_graphs.connected_watts_strogatz_graph.html[API Docs] for more details.
<2> If the nxmetix package is available, distribute the graph using the metis partition method,
and write it out to `fname`
<3> If nxmetis is not avaiable, distribute the graph using the default random parition method,
and write it out to `fname`

See <TODO: api doc link> the API documentation for `write_network` for more information.

== The Rumor Model Implementation
The Rumor Model implementation follows the typical repast4py stucture, and consists of the following parts.

1. A `RumorAgent` class that implements the agent state and behavior.
2. A `Model` class responsible for initialization and managing the simulation.
3. A `create_rumor_agent` function used to create the Rumor agents when creating the
network from a saved file.
4. A `restore_agent_function` function used to create an individual `RumorAgent` when that
`RumorAgent` has been ghosted (i.e., created as a ghost agent) on another process rank.
5. A `run` function that creates and starts the simulation
6. An `if __name__ == "__main__"` block that allows the simulation to be run
from the command line.

=== The Rumor Agent
The rumor model's agent is a simple class with a single `received_rumor` boolean attribute that
specifies whether or not the agent has received the rumor. It also has the canonical `save` and
`update` methods used to move or copy the agent bewteen processes and to update the state of a
ghost agent from its originating process rank.

[source,python,numbered]
----
class RumorAgent(core.Agent):    <1>

    def __init__(self, nid: int, agent_type: int, rank: int, received_rumor=False):
        super().__init__(nid, agent_type, rank)    <2>
        self.received_rumor = received_rumor    <3>

    def save(self):    <4>
        """Saves the state of this agent as tuple.

        A non-ghost agent will save its state using this
        method, and any ghost agents of this agent will
        be updated with that data (self.received_rumor).

        Returns:
            The agent's state
        """
        return (self.uid, self.received_rumor)

    def update(self, data: bool):    <5>
        """Updates the state of this agent when it is a ghost
        agent on some rank other than its local one.

        Args:
            data: the new agent state (received_rumor)
        """
        if not self.received_rumor and data:
            # only update if the received rumor state
            # has changed from false to true
            model.rumor_spreaders.append(self)
            self.received_rumor = data
----
<1> RumorAgent extends `repast4py.core.agent` as is required by all repast4py agents
<2> Calls the `core.Agent` constructor, passing the node id, agent_type, and originating rank.
Together these will create a globally unique id for this agent.
<3> The `received_rumor` boolean specified whether the agent has received the rumor
and is able to spread it.
<4> The required `save` method for saving the agent's state as a tuple. This state
can be used to update ghosts of this agent on other ranks.
<5> The required `update` method for updating ghosts from saved agent state. Here,
we only update if the `received_rumor` state has changed from False to True. If so,
then add this agent to the Model's list of rumor spreading agents (<<_seeding_the_rumors>>). 

=== The Model Class
The Model class encapsulates the simulation, and is responsible for initialization: scheduling events, creating agents and the network, and logging. In addition, the scheduled events
that drive the simulation forward are methods of the model class. 

In the `Model` constructor, we create the simulation schedule, 
the network, seed the network the rumors, and initialize the _loggers_ that
we use to log the rumour counts to a file.

==== Scheduling Events
The SharedScheduledRunner class encapsulates a dynamic schedule of executable events shared and
synchronized across processes. Events are added to the scheduled for execution at a particular _tick_.
The first valid tick is 0. Events will be executed in tick order, earliest before latest. Events
scheduled for the same tick will be executed in the order in which they
were added. If during the execution of a tick, an event is scheduled
before the executing tick (i.e., scheduled to occur in the past) then
that event is ignored. The scheduled is synchronized across process ranks
by determining the global cross-process minimum next scheduled even time, and executing events
for that time. In this way, no schedule runs ahead of any other. In practice an
event is no-argument function or method.

[source,python,numbered]
----
from repast4py import core, random, schedule, logging, parameters
...
class Model:

    def __init__(self, comm, params):
        self.runner = schedule.init_schedule_runner(comm)    <1>
        self.runner.schedule_repeating_event(1, 1, self.step)    <2>
        self.runner.schedule_stop(params['stop.at'])    <3>
        self.runner.schedule_end_event(self.at_end)    <4>
        ...
----
<1> Before any events can be scheduled, the schedule runner must be initialized.
<2> Repeating events are scheduled with `schedule.repeating_event`. The first argument
is the start tick, and the second is the frequency to repeat at. This schedules `Model.step`
on this instance of the model to execute starting at tick 1 and then every tick thereafter. 
<3> `schedule_stop` schedules the tick at which the simulation should stop. At this tick,
events will no longer be popped off the schedule and executed.
<4> `schedule_end_event` can be used to schedule methods that perform some sort of 
_clean up_ type operation when the simulation ends, closing a log file, for example.
This is called when at the time of simulation stop as specified with `schedule_stop`.

TIP: Once the default scheduler runner has been initialized with `schedule.init_schedule_runner`, you can get a reference to it with `schedule.runner()`. See the schedule model API documentation for
more information on different ways to schedule events (methods and functions).

IMPORTANT: A simulation stopping time must be set with `schedule_stop`. Without a stopping time
the simulation will continue to run, seeming to hang if there are no events to execute, or
continuing to execute any scheduled events without stopping. The stopping time does not
need to be set during initialization, but can be set during a simulation run when a
stopping condition is reached, for example.

==== Creating the Network
As described in <<_the_network>> the rumor model network is initialized
from a file. The `repast4py.network.read_network` function reads this
file and creates a SharedNetwork instance from the network description
in the file.

[source,python,numbered]
----
fpath = params['network_file']    <1>
self.context = ctx.SharedContext(comm)    <2>
read_network(fpath, self.context, create_rumor_agent, restore_agent)    <3>
self.net = self.context.get_projection('rumor_network')    <4>
----
<1> Get the path to the file describing the network from the parameters dictionary.
<2> Create a context to hold the agents and the network projection.
<3> Create the network from the named file, using the `create_rumor_agent`, and
`restore_agent` functions to create the agents and their necessary ghosts (<<_creating_and_restoring_rumoragents>>). The created network is added to the 
specified context.
<4> Get a reference to the named network from the context. The network
input file specifies the network name on its first line.

==== Seeding the Rumors
We seed the network with some initial rumor spreaders by selecting some parameterized number of
agents and setting their `received_rumor` attribute to True. These agents
are added the Model's list of rumor spreaders.

[source,python,numbered]
----
def __init__(self, comm, params):
    ...
    self.rumor_spreaders = []
    self.rank = comm.Get_rank()
    self._seed_rumor(params['initial_rumor_count'], comm)
----

The `seed_rumor` function uses MPI's Scatter function to send
each rank the number of agents to initialize as rumor spreaders. 
An MPI4Py scatter call takes a collection or array of values created on 
one rank (the root rank) and sends the _ith_ element
of that collection or array to rank _i_. So for example,
rank 0 gets the _0th_ element, rank 1 gets the _first_, and
so on. In `seed_rumor`, we use a numpy array of ints as the array
to scatter and the _ith_ element of the array is the number of rumor
spreaders to initialize on rank _i_.

[source,python,numbered]
----
def _seed_rumor(self, init_rumor_count: int, comm):
    world_size = comm.Get_size()    <1>
    # np array of world size, the value of i'th element of the array
    # is the number of rumors to seed on rank i.
    rumor_counts = np.zeros(world_size, np.int32)    <2>
    if (self.rank == 0):    <3>
        for _ in range(init_rumor_count):
            idx = random.default_rng.integers(0, high=world_size)
            rumor_counts[idx] += 1

    rumor_count = np.empty(1, dtype=np.int32)    <4>
    comm.Scatter(rumor_counts, rumor_count, root=0)     <5>

    for agent in self.context.agents(count=rumor_count[0], shuffle=True):    <6>
        agent.received_rumor = True
        self.rumor_spreaders.append(agent)
----
<1> Get the total number of ranks over which the simulation is distributed.
<2> Initialize a numpy array of `world_size` with zeros. `rumor_counts` 
will hold the number of initial rumor spreaders for each rank.
<3> If this Model's rank is 0, then randomly select an index into the
`rumor_counts` array, and increment the value at that index by one. Do
this for a number of times equal to the initial number of rumors to seed.
<4> Create an empty array of size 1 to receive the number of rumors
from the Scatter call.
<5> Scatter the values in `rumor_counts` from root rank 0 into the `rumor_count`
array on all the ranks. `rumor_count` now holds the number of initial
rumor spreaders assigned to the current rank.
<6> Using the `SharedContext.agents` method, get an iterator over a number of agents equal to 
`rumor_count` at random (`shuffle=True`). Set each one of those agent's `received_rumor`
attribute to True, and add each one to the Model's `rumor_spreaders` list.

TIP: Using MPI4Py's Scatter in this way is a useful method for 
randomly dividing up some total initiailization value among ranks. In
the RumorModel, we tell each rank to initialize some number of rumor spreaders where
the total of all these values is the number of initial rumor spreaders
specified by the input parameter.

==== Logging
Logging refers to gathering simulation output data and writing it to a file. There are
two types of logging supported by repast4py.

1. Tabular logging in which the user supplies a row values to be logged, and repast4py 
concatenates these rows across processes and writes them to a file. This is useful
for logging events and individual agent attributes. See the `repast4py.logging.TabularLogger`
API for more information.

2. Reducing-type logging where the user supplies the aggregate values to be logged
in the form of a Python `dataclasses.dataclass` and repast4py performs a cross-process
reduce-type operation on those values. In this type of logging, the user creates a _logger_
that is responsible for logging a Python `dataclass` field's or fields' value, and performing 
the reduction 
operation on the field(s). These loggers are then added to
a `logging.ReducingDataSet`. Calling `logging.ReducingDataSet.log(tick)` will log the
current value of the dataclass fields in the loggers and perform the cross-process
reduction. See the `logging` module API for more information.

The Rumor Model uses the second of these log types. The dataclass that we log records
the total number of rumor spreaders and the number of new rumor spreaders added during
a tick.

[source,python,numbered]
----
@dataclass
class RumorCounts:
    total_rumor_spreaders: int
    new_rumor_spreaders: int
----

[source,python,numbered]
----
def __init__(self, comm, params):
    ...

    rumored_count = len(self.rumor_spreaders)    <1>
    self.counts = RumorCounts(rumored_count, rumored_count)    <2>
    loggers = logging.create_loggers(self.counts, op=MPI.SUM, rank=self.rank)    <3>
    self.data_set = logging.ReducingDataSet(loggers, MPI.COMM_WORLD, 
                                            params['counts_file'])    <4>
    self.data_set.log(0)    <5>
----
<1> Get the current number of rumor spreaders immediately after rumor seeding.
<2> Create the RumorCount instance, setting the `total_rumor_spreaders` and `new_rumor_spreaders`
to the current number of rumor spreaders.
<3> Create a list of loggers that use `self.counts` as the source of the data to log,
and that peforms a cross process rank summation of that data. The `names` argument is not 
specified, so the `RumorCount` field names will be used as column headers.
<4> Create a `logging.ReducingDataSet` from the list loggers where `params['counts_file]`
is the name of the file to log to.
<5> Log the initial (_tick 0_) values from `self.counts`.

==== Scheduled Methods
In <<_scheduling_events>> we saw how to schedule events that repeat and that execute
when the simulation ends. In practice, the events to be scheduled are methods in the
model class. The methods are called according to how they are scheduled, driving the
simulation forward. The `step` method is scheduled to execute starting
at tick 1 and then every tick thereafter. It is in the step method that the rumor spreading
is implemented. The implemention is a nested loop that iterates through all the network neighbors
of each rumor spreader. If the network neighbor has not yet received a rumor, is local
to the current rank, and the draw against the probability of a rumor spreading is successful then
we set the neighbors received_rumor attribute to True, and ultimately add it to the 
Model's list of rumor spreaders.

NOTE: Each `repast4py.network.SharedNetwork` instance contains a reference to a `networkx.
Graph` instance named `graph`. Use `graph` for any network queries that do not change the
structure of the network. For example, `graph.neighbors(n)` will return the network neighbors
of agent n. See the https://networkx.org/documentation/stable/reference/index.html[networkx API documentation] for more info.

[source,python,numbered]
----
def step(self):
    new_rumor_spreaders = []    <1>
    rng = random.default_rng
    for agent in self.rumor_spreaders:    <2>
        for ngh in self.net.graph.neighbors(agent):
            if not ngh.received_rumor and ngh.local_rank == self.rank  \
               and rng.uniform() <= self.rumor_prob:
                ngh.received_rumor = True
                new_rumor_spreaders.append(ngh)

    self.rumor_spreaders += new_rumor_spreaders    <3>
    self.counts.total_rumor_spreaders = len(self.rumor_spreaders)    <4>
    self.counts.new_rumor_spreaders = len(new_rumor_spreaders)    <5>
    self.data_set.log(self.runner.schedule.tick)    <6>

    self.context.synchronize(restore_agent)    <7>
----
<1> Create a list to hold any new rumor speaders, i.e., agents whose `received_rumor` attribute
is set to True during this iteration.
<2> For each rumor spreader, iterate through all its network neighbors. If the network neighbor
has not yet received a rumor, is local to the current rank, and the draw against 
the probability of a rumor spreading is successful then we set the neighbors received_rumor 
attribute to True, and add it to the list of new rumor spreaders. 
<3> Add the new rumor spreaders to the list of current rumor spreaders.
<4> Set the total number of rumor spreaders on the `self.counts` log.
<5> Set the new number of rumor spreaders on the `self.counts` log.
<6> Log the `self.count` values for the current tick.
<7> Synchronize the model state across all ranks. This will update all
the ghost agent state, calling `RumorAgent.update` on the ghost agents.

NOTE: The list of rumor spreaders (`rumor_spreaders`) can contain ghost agents. As we saw in
<<_the_rumor_agent>> `RumorAgent.update` is called to update the state of ghost agents. If
the update changes the `received_rumor` attribute to True, then that ghost agent is added to
the Model's list of rumor spreaders.

IMPORTANT: Never update the state of a ghost agent. A ghost agent is a mirror of an agent local
to some other process. The ghost agent's state will be updated from that local source agent
during the `synchronize` call overwriting any changes. The Rumor Model checks if the local rank
of a rumor spreader's network neighbor is the current rank (`ngh.local_rank == self.rank`)
before updating the neighbors state in order to avoid update ghost state.

The final event (`self.runner.schedule_end_event(self.at_end)`) is scheduled to call
`Model.at_end` when the simulation ends. This method closes the logging data set, 
insuring that any remaining unwriten data is writen out. 

[source,python,numbered]
----
def at_end(self):
    self.data_set.close()
----

IMPORTANT: Do not forget to call `close` on your logging class instances when the simulation ends.

=== Creating and Restoring RumorAgents
RumorAgents are created during the `read_network` call in the `Model`
constructor. 

[source,python,numbered]
----
read_network(fpath, self.context, create_rumor_agent, restore_agent)
----

There, as part of creating the network, the nodes (i.e., agents)
of that network are also created. Each rank creates the nodes that are assigned to
it using the passed in `create_rumor_agent` function.

[source,python,numbered]
----
def create_rumor_agent(nid, agent_type, rank, **kwargs):    <1>
    return RumorAgent(nid, agent_type, rank)
----
<1> The nid, agent_type, and rank arguments are read from the network
input file and passed to this function. See the `repast4py.network.read_network`
API documentation for more info. TODO: API Link.


As described in <<_the_network>>, when an edge links two nodes
on different ranks, repast4py will create _ghost agents_ as necessary and
create an edge between the ghosts and the local agents. The `restore_agent` function is 
used to create the ghost on the rank it is ghosted to, using the state from 
the source agents `save` method.

[source,python,numbered]
----
def restore_agent(agent_data):    <1>
    uid = agent_data[0]
    return RumorAgent(uid[0], uid[1], uid[2], agent_data[1])
----
<1> `agent_data` is the tuple produced by an agent's `save` method.

=== Running the Simulation

The simulation is run from the command line. Assuming you are in the 
examples/rumor directory.

`mpirun -n 4 python rumor.py rumor_model.yaml`

Here we are running the simulation with 4 process ranks and the model input parameters are
in the `rumor_model.yaml` file.

An `if __name__ == '__main__'` code block is used to parse the input parameters and
run the simulation. Within that, utility functions in the `repast4py.parameters` module 
parse both the command line and model input parameter files

[source,python,numbered]
----
if __name__ == "__main__":
    parser = parameters.create_args_parser()    <1>
    args = parser.parse_args()   <2>
    params = parameters.init_params(args.parameters_file, args.parameters)    <3>
    run(params)
----
<1> Creates the default command line argument parser.
<2> Parse the command line into its arguments using that default parser
<3> Create the model input parameters dictionary from those arguments using
`parameters.init_params`.

The default command line parser created with `parameters.create_args_parser` accepts
a path to a yaml format parameters input file, and a json format dictionary string
that will override parameters in the parameters file.

```
$ python examples/rndwalk/rndwalk.py -h
usage: rumor.py [-h] parameters_file [parameters]

positional arguments:
  parameters_file  parameters file (yaml format)
  parameters       json parameters string

optional arguments:
  -h, --help       show this help message and exit
```

`parameters.init_params` takes the parameters file and the json string and creates a dictionary
of model input parameters whose keys are the parameter names and values are the parameter values.

If the parameters file or the json input contains a parameter named `random.seed`,
the default random number generator (i.e., `repast4py.random.default_rng`) is initialized
with that seed. See the `repast4py.parameters` API documenation for more information.

Lastly we have a simple `run` function that creates the `Model` class and calls its
`start` method which starts the simulation by starting schedule execution. This `run` function is called
in the `if __name__ == '__main__'` code block.

[source,python,numbered]
----
def run(params: Dict):
    model = Model(MPI.COMM_WORLD, params)
    model.start()

class Model:

    def start(self):
        self.runner.execute()    <1>
----
<1> Start the simulation by executing the schedule which
calls the scheduled methods at the appropriate times and frequency.

NOTE: The code in the `run` function could be moved to the `if __name__ == '__main__'` code block,
but it is often useful to have an entry type function that initializes and starts a simulation.

